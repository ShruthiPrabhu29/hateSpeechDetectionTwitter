{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bi-LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BiLSTm +Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "Allowing embedding learning: True\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16132\n",
      "Vocabs loaded from pickled files.\n",
      "X and y loaded from pickled files.\n",
      "max seq length is 26\n",
      "2574 embedding missed\n",
      "Model variation is Bi-LSTM\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 26, 200)       3188600     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 26, 200)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 100)           100400      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 100)           0           bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 3)             303         dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 3)             0           dense_1[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,289,303\n",
      "Trainable params: 3,289,303\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.829377.\tAccuracy: 0.676786\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.742471.\tAccuracy: 0.715513\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.665685.\tAccuracy: 0.748065\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.391110.\tAccuracy: 0.848661\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.360438.\tAccuracy: 0.863951\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.341510.\tAccuracy: 0.872842\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.248251.\tAccuracy: 0.909375\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.231282.\tAccuracy: 0.916853\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.226335.\tAccuracy: 0.920685\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.177153.\tAccuracy: 0.939955\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.171128.\tAccuracy: 0.940848\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.169001.\tAccuracy: 0.942187\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.134730.\tAccuracy: 0.955804\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.135225.\tAccuracy: 0.956250\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.131506.\tAccuracy: 0.956324\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.107461.\tAccuracy: 0.963393\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.108758.\tAccuracy: 0.962723\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.107973.\tAccuracy: 0.962723\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.092774.\tAccuracy: 0.967857\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.098397.\tAccuracy: 0.966071\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.099737.\tAccuracy: 0.964807\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.085249.\tAccuracy: 0.968973\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.092205.\tAccuracy: 0.968415\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.091572.\tAccuracy: 0.967560\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.070003.\tAccuracy: 0.974330\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.069635.\tAccuracy: 0.974888\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.071074.\tAccuracy: 0.973884\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.067884.\tAccuracy: 0.975893\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.066962.\tAccuracy: 0.975781\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.069013.\tAccuracy: 0.974330\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86      1069\n",
      "           1       0.73      0.64      0.68       223\n",
      "           2       0.71      0.57      0.63       322\n",
      "\n",
      "    accuracy                           0.79      1614\n",
      "   macro avg       0.75      0.70      0.72      1614\n",
      "weighted avg       0.79      0.79      0.79      1614\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.858671.\tAccuracy: 0.657143\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.786439.\tAccuracy: 0.682701\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.695432.\tAccuracy: 0.720833\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.390951.\tAccuracy: 0.844196\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.359308.\tAccuracy: 0.859263\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.326399.\tAccuracy: 0.873661\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.216754.\tAccuracy: 0.919420\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.208833.\tAccuracy: 0.922991\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.197961.\tAccuracy: 0.927530\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.147455.\tAccuracy: 0.947768\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.150990.\tAccuracy: 0.945759\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.145421.\tAccuracy: 0.947991\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.117936.\tAccuracy: 0.956250\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.121895.\tAccuracy: 0.955915\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.121477.\tAccuracy: 0.956101\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.099928.\tAccuracy: 0.963393\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.102110.\tAccuracy: 0.962388\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.106701.\tAccuracy: 0.960714\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.083497.\tAccuracy: 0.970759\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.089168.\tAccuracy: 0.967299\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.089618.\tAccuracy: 0.968229\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.071282.\tAccuracy: 0.975670\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.073447.\tAccuracy: 0.973884\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.076607.\tAccuracy: 0.972173\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.063434.\tAccuracy: 0.974777\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.068810.\tAccuracy: 0.973772\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.070572.\tAccuracy: 0.972991\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.049743.\tAccuracy: 0.979911\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.057036.\tAccuracy: 0.977344\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.060655.\tAccuracy: 0.976414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.79      0.83      1100\n",
      "           1       0.66      0.71      0.68       182\n",
      "           2       0.60      0.76      0.67       332\n",
      "\n",
      "    accuracy                           0.78      1614\n",
      "   macro avg       0.71      0.75      0.73      1614\n",
      "weighted avg       0.79      0.78      0.78      1614\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.822731.\tAccuracy: 0.664509\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.710575.\tAccuracy: 0.716853\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.637149.\tAccuracy: 0.748363\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.369345.\tAccuracy: 0.852455\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.332621.\tAccuracy: 0.868304\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.306714.\tAccuracy: 0.879092\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.211956.\tAccuracy: 0.920089\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.204011.\tAccuracy: 0.922879\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.194393.\tAccuracy: 0.928274\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.149009.\tAccuracy: 0.945759\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.148434.\tAccuracy: 0.946987\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.147643.\tAccuracy: 0.946949\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.124492.\tAccuracy: 0.953125\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.119184.\tAccuracy: 0.956696\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.120975.\tAccuracy: 0.957440\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.106590.\tAccuracy: 0.959152\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.104686.\tAccuracy: 0.960379\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.103173.\tAccuracy: 0.961682\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.089312.\tAccuracy: 0.966295\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.091624.\tAccuracy: 0.965960\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.093317.\tAccuracy: 0.965253\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.074118.\tAccuracy: 0.972098\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.073776.\tAccuracy: 0.972768\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.074978.\tAccuracy: 0.972991\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.061826.\tAccuracy: 0.975670\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.065511.\tAccuracy: 0.975670\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.068031.\tAccuracy: 0.974554\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.063790.\tAccuracy: 0.976562\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.063771.\tAccuracy: 0.975446\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.063717.\tAccuracy: 0.975521\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      1061\n",
      "           1       0.69      0.67      0.68       218\n",
      "           2       0.66      0.67      0.66       334\n",
      "\n",
      "    accuracy                           0.78      1613\n",
      "   macro avg       0.73      0.73      0.73      1613\n",
      "weighted avg       0.78      0.78      0.78      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.833712.\tAccuracy: 0.660045\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.740878.\tAccuracy: 0.700670\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.661087.\tAccuracy: 0.737054\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.376957.\tAccuracy: 0.852902\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.346123.\tAccuracy: 0.865179\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.319244.\tAccuracy: 0.876339\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.236280.\tAccuracy: 0.909821\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.218068.\tAccuracy: 0.918192\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.208173.\tAccuracy: 0.922991\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.169609.\tAccuracy: 0.941518\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.159526.\tAccuracy: 0.944085\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.154108.\tAccuracy: 0.945685\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.131940.\tAccuracy: 0.955134\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.127531.\tAccuracy: 0.956473\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.124013.\tAccuracy: 0.957961\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.106082.\tAccuracy: 0.963839\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.104592.\tAccuracy: 0.963839\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.102632.\tAccuracy: 0.964286\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.086607.\tAccuracy: 0.973884\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.088712.\tAccuracy: 0.970647\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.087759.\tAccuracy: 0.969643\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.071967.\tAccuracy: 0.973661\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.072726.\tAccuracy: 0.973437\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.073652.\tAccuracy: 0.972396\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.068767.\tAccuracy: 0.974777\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.069676.\tAccuracy: 0.974442\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.071008.\tAccuracy: 0.972396\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.062431.\tAccuracy: 0.975223\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.064163.\tAccuracy: 0.975000\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.065727.\tAccuracy: 0.974851\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      1126\n",
      "           1       0.70      0.58      0.64       185\n",
      "           2       0.61      0.69      0.65       302\n",
      "\n",
      "    accuracy                           0.79      1613\n",
      "   macro avg       0.72      0.71      0.71      1613\n",
      "weighted avg       0.79      0.79      0.79      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.803551.\tAccuracy: 0.674107\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.690829.\tAccuracy: 0.723996\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.620963.\tAccuracy: 0.754018\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.356908.\tAccuracy: 0.861161\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.325284.\tAccuracy: 0.872879\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.307035.\tAccuracy: 0.879836\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.228834.\tAccuracy: 0.917411\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.211375.\tAccuracy: 0.920647\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.205636.\tAccuracy: 0.923512\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.167598.\tAccuracy: 0.938839\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.156604.\tAccuracy: 0.942857\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.152167.\tAccuracy: 0.944345\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.135055.\tAccuracy: 0.951786\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.126308.\tAccuracy: 0.954799\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.125078.\tAccuracy: 0.954911\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.100063.\tAccuracy: 0.966295\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.103521.\tAccuracy: 0.963281\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.104826.\tAccuracy: 0.962798\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.084800.\tAccuracy: 0.969196\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.089260.\tAccuracy: 0.968750\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.091956.\tAccuracy: 0.967262\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.070902.\tAccuracy: 0.973661\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.073873.\tAccuracy: 0.974665\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.078364.\tAccuracy: 0.972619\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.064163.\tAccuracy: 0.976786\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.068896.\tAccuracy: 0.976116\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.074449.\tAccuracy: 0.973661\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.058028.\tAccuracy: 0.976786\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.060071.\tAccuracy: 0.977567\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.065636.\tAccuracy: 0.975670\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.86      0.85      1088\n",
      "           1       0.73      0.65      0.68       193\n",
      "           2       0.68      0.66      0.67       332\n",
      "\n",
      "    accuracy                           0.80      1613\n",
      "   macro avg       0.75      0.72      0.74      1613\n",
      "weighted avg       0.79      0.80      0.79      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.877528.\tAccuracy: 0.642411\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.741343.\tAccuracy: 0.701674\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.667929.\tAccuracy: 0.735045\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.374845.\tAccuracy: 0.858705\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.342940.\tAccuracy: 0.868862\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.322078.\tAccuracy: 0.878274\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.235915.\tAccuracy: 0.913839\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.216834.\tAccuracy: 0.918973\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.207075.\tAccuracy: 0.923214\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.181656.\tAccuracy: 0.935268\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.169802.\tAccuracy: 0.939621\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.162148.\tAccuracy: 0.942783\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.134173.\tAccuracy: 0.950223\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.131695.\tAccuracy: 0.952121\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.128683.\tAccuracy: 0.954167\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.113852.\tAccuracy: 0.960491\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.113956.\tAccuracy: 0.959933\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.110309.\tAccuracy: 0.961384\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.097045.\tAccuracy: 0.965402\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.092531.\tAccuracy: 0.966741\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.092349.\tAccuracy: 0.966295\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.092015.\tAccuracy: 0.968527\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.088646.\tAccuracy: 0.969308\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.084995.\tAccuracy: 0.970313\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.071869.\tAccuracy: 0.972545\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.071794.\tAccuracy: 0.974665\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.073562.\tAccuracy: 0.973586\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.059926.\tAccuracy: 0.979911\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.064638.\tAccuracy: 0.978460\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.065981.\tAccuracy: 0.976414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.88      1114\n",
      "           1       0.71      0.71      0.71       180\n",
      "           2       0.72      0.70      0.71       319\n",
      "\n",
      "    accuracy                           0.83      1613\n",
      "   macro avg       0.77      0.76      0.77      1613\n",
      "weighted avg       0.83      0.83      0.83      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.855826.\tAccuracy: 0.653348\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.740587.\tAccuracy: 0.705915\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.667566.\tAccuracy: 0.735565\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.376392.\tAccuracy: 0.852232\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.343603.\tAccuracy: 0.866964\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.326227.\tAccuracy: 0.873512\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.240768.\tAccuracy: 0.909375\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.226030.\tAccuracy: 0.914732\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.215176.\tAccuracy: 0.919271\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.163929.\tAccuracy: 0.939286\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.158129.\tAccuracy: 0.941071\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.156909.\tAccuracy: 0.941592\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.133364.\tAccuracy: 0.952902\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.128570.\tAccuracy: 0.954576\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.128559.\tAccuracy: 0.954464\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.103900.\tAccuracy: 0.962946\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.102385.\tAccuracy: 0.961942\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.103348.\tAccuracy: 0.961235\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.086625.\tAccuracy: 0.971429\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.087277.\tAccuracy: 0.969308\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.087586.\tAccuracy: 0.968899\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.075462.\tAccuracy: 0.970536\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.078483.\tAccuracy: 0.970647\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.080783.\tAccuracy: 0.969792\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.065887.\tAccuracy: 0.976562\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.070703.\tAccuracy: 0.975000\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.074068.\tAccuracy: 0.972693\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.062870.\tAccuracy: 0.976562\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.065735.\tAccuracy: 0.976339\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.067610.\tAccuracy: 0.974628\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.84      0.85      1134\n",
      "           1       0.68      0.68      0.68       201\n",
      "           2       0.61      0.69      0.65       278\n",
      "\n",
      "    accuracy                           0.79      1613\n",
      "   macro avg       0.72      0.74      0.72      1613\n",
      "weighted avg       0.80      0.79      0.79      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.919181.\tAccuracy: 0.629018\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.761593.\tAccuracy: 0.692746\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.682241.\tAccuracy: 0.726562\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.367843.\tAccuracy: 0.859152\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.335899.\tAccuracy: 0.871317\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.321180.\tAccuracy: 0.876563\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.236655.\tAccuracy: 0.911830\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.219971.\tAccuracy: 0.919085\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.211664.\tAccuracy: 0.924182\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.170012.\tAccuracy: 0.939286\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.159069.\tAccuracy: 0.943415\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.157212.\tAccuracy: 0.944048\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.133935.\tAccuracy: 0.953348\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.129973.\tAccuracy: 0.954129\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.129724.\tAccuracy: 0.954613\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.113197.\tAccuracy: 0.962946\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.111257.\tAccuracy: 0.962388\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.106584.\tAccuracy: 0.963021\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.094787.\tAccuracy: 0.965848\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.093964.\tAccuracy: 0.965513\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.093629.\tAccuracy: 0.965104\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.083913.\tAccuracy: 0.970982\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.081459.\tAccuracy: 0.972545\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.080946.\tAccuracy: 0.972247\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.074525.\tAccuracy: 0.971205\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.075203.\tAccuracy: 0.972321\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.073889.\tAccuracy: 0.972917\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.061885.\tAccuracy: 0.977232\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.062316.\tAccuracy: 0.976674\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.063193.\tAccuracy: 0.976562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86      1131\n",
      "           1       0.66      0.67      0.67       180\n",
      "           2       0.65      0.68      0.66       302\n",
      "\n",
      "    accuracy                           0.80      1613\n",
      "   macro avg       0.73      0.73      0.73      1613\n",
      "weighted avg       0.80      0.80      0.80      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.895557.\tAccuracy: 0.645982\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.770762.\tAccuracy: 0.695201\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.690093.\tAccuracy: 0.730878\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.381077.\tAccuracy: 0.855804\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.351613.\tAccuracy: 0.866964\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.338831.\tAccuracy: 0.873661\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.254623.\tAccuracy: 0.907813\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.239249.\tAccuracy: 0.912165\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.230882.\tAccuracy: 0.915699\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.188741.\tAccuracy: 0.930134\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.181197.\tAccuracy: 0.933259\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.174496.\tAccuracy: 0.936235\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.144232.\tAccuracy: 0.949554\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.138264.\tAccuracy: 0.951674\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.137088.\tAccuracy: 0.950744\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.118686.\tAccuracy: 0.956696\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.117154.\tAccuracy: 0.956138\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.118447.\tAccuracy: 0.955432\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.105279.\tAccuracy: 0.960714\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.099551.\tAccuracy: 0.963951\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.097898.\tAccuracy: 0.964360\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.087355.\tAccuracy: 0.968973\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.086083.\tAccuracy: 0.969643\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.088712.\tAccuracy: 0.968899\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.084322.\tAccuracy: 0.970536\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.080798.\tAccuracy: 0.971540\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.081948.\tAccuracy: 0.970833\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.071754.\tAccuracy: 0.974330\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.072930.\tAccuracy: 0.973326\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.075832.\tAccuracy: 0.972619\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.83      0.86      1100\n",
      "           1       0.67      0.76      0.72       187\n",
      "           2       0.65      0.76      0.70       326\n",
      "\n",
      "    accuracy                           0.81      1613\n",
      "   macro avg       0.74      0.78      0.76      1613\n",
      "weighted avg       0.82      0.81      0.81      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.958984.\tAccuracy: 0.629687\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.817008.\tAccuracy: 0.678348\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.729431.\tAccuracy: 0.712054\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.419827.\tAccuracy: 0.837054\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.381674.\tAccuracy: 0.851004\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.362874.\tAccuracy: 0.860045\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.263555.\tAccuracy: 0.900223\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.249278.\tAccuracy: 0.906362\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.240440.\tAccuracy: 0.909673\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.197597.\tAccuracy: 0.930357\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.187705.\tAccuracy: 0.931250\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.182398.\tAccuracy: 0.934747\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.151895.\tAccuracy: 0.944866\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.150049.\tAccuracy: 0.945089\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.148983.\tAccuracy: 0.945312\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.114432.\tAccuracy: 0.960045\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.114311.\tAccuracy: 0.958594\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.113305.\tAccuracy: 0.958780\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.104930.\tAccuracy: 0.965848\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.102784.\tAccuracy: 0.965625\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.104142.\tAccuracy: 0.964583\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.087126.\tAccuracy: 0.968304\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.087452.\tAccuracy: 0.969643\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.091994.\tAccuracy: 0.967485\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.080084.\tAccuracy: 0.972321\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.081049.\tAccuracy: 0.971094\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.083193.\tAccuracy: 0.970238\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.064348.\tAccuracy: 0.977009\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.070043.\tAccuracy: 0.974888\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.071806.\tAccuracy: 0.974479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86      1107\n",
      "           1       0.77      0.69      0.73       186\n",
      "           2       0.63      0.69      0.66       320\n",
      "\n",
      "    accuracy                           0.80      1613\n",
      "   macro avg       0.75      0.75      0.75      1613\n",
      "weighted avg       0.81      0.80      0.80      1613\n",
      "\n",
      "macro results are\n",
      "average precision is 0.799406\n",
      "average recall is 0.795811\n",
      "average f1 is 0.796472\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "!python lstm_bi.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --initialize-weights random --learn-embeddings --epochs 10 --batch-size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BiLSTM +Random + GBDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 200\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16132\n",
      "Model Type: gradient_boosting\n",
      "Precision(avg): 0.922 (+/- 0.010)\n",
      "Recall(avg): 0.922 (+/- 0.010)\n",
      "F1-score(avg): 0.921 (+/- 0.010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed: 13.2min finished\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier.py gradient_boosting bi_lstm_random.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bi_LSTM + Random + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 200\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16132\n",
      "Model Type: logistic\n",
      "Precision(avg): 0.929 (+/- 0.006)\n",
      "Recall(avg): 0.929 (+/- 0.006)\n",
      "F1-score(avg): 0.929 (+/- 0.007)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed:   17.3s finished\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier.py logistic bi_lstm_random.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LSTM + Random + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 200\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16132\n",
      "Model Type: logistic\n",
      "Precision(avg): 0.929 (+/- 0.010)\n",
      "Recall(avg): 0.930 (+/- 0.010)\n",
      "F1-score(avg): 0.929 (+/- 0.010)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed:   17.7s finished\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier.py logistic lstm_random.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BiLSTM + Random + Hybrid Feature (TF_IDF_WA)+ LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 200\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16132\n",
      "16132 200 200 16132\n",
      "Model Type: logistic\n",
      "Precision(avg): 0.935 (+/- 0.007)\n",
      "Recall(avg): 0.936 (+/- 0.006)\n",
      "F1-score(avg): 0.935 (+/- 0.006)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed:   60.0s finished\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier_tfidf.py logistic bi_lstm_random.h5    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Bi-LSTM with Glove (Basic Preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE embedding: GloVe/glove.twitter.27B.200d.txt\n",
      "Embedding Dimension: 200\n",
      "Allowing embedding learning: True\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16132\n",
      "Vocabs loaded from pickled files.\n",
      "X and y loaded from pickled files.\n",
      "max seq length is 26\n",
      "2574 embedding missed\n",
      "Model variation is Bi-LSTM\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "embedding_1 (Embedding)          (None, 26, 200)       3188600     embedding_input_1[0][0]          \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 26, 200)       0           embedding_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional)  (None, 26, 100)       100400      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "globalmaxpooling1d_1 (GlobalMaxP (None, 100)           0           bidirectional_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 24)            2424        globalmaxpooling1d_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 24)            0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 3)             75          activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 3)             0           dense_2[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,291,499\n",
      "Trainable params: 3,291,499\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "KFold(n_splits=10, random_state=42, shuffle=True)\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.897761.\tAccuracy: 0.619643\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.761754.\tAccuracy: 0.672768\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.675347.\tAccuracy: 0.713616\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.457063.\tAccuracy: 0.814509\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.433015.\tAccuracy: 0.822991\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.419815.\tAccuracy: 0.830357\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.366768.\tAccuracy: 0.845536\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.350934.\tAccuracy: 0.854464\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.341253.\tAccuracy: 0.860938\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.297215.\tAccuracy: 0.882143\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.287327.\tAccuracy: 0.884598\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.281153.\tAccuracy: 0.887649\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.235105.\tAccuracy: 0.906920\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.229770.\tAccuracy: 0.908147\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.225461.\tAccuracy: 0.911012\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.196587.\tAccuracy: 0.926116\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.189181.\tAccuracy: 0.926897\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.186645.\tAccuracy: 0.927604\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.162528.\tAccuracy: 0.939286\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.156501.\tAccuracy: 0.940179\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.155808.\tAccuracy: 0.940253\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.143843.\tAccuracy: 0.949107\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.138250.\tAccuracy: 0.948884\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.135966.\tAccuracy: 0.949182\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.122229.\tAccuracy: 0.953571\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.115911.\tAccuracy: 0.957143\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.114659.\tAccuracy: 0.958185\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.107619.\tAccuracy: 0.958929\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.102680.\tAccuracy: 0.961830\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.103446.\tAccuracy: 0.961458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.92      0.87      1069\n",
      "           1       0.83      0.59      0.69       223\n",
      "           2       0.77      0.59      0.67       322\n",
      "\n",
      "    accuracy                           0.81      1614\n",
      "   macro avg       0.81      0.70      0.74      1614\n",
      "weighted avg       0.81      0.81      0.80      1614\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.722924.\tAccuracy: 0.712500\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.615925.\tAccuracy: 0.753795\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.562500.\tAccuracy: 0.775149\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.434376.\tAccuracy: 0.820089\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.412119.\tAccuracy: 0.830692\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.397885.\tAccuracy: 0.838095\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.347377.\tAccuracy: 0.857366\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.329314.\tAccuracy: 0.865737\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.317614.\tAccuracy: 0.872842\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.271389.\tAccuracy: 0.888616\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.257355.\tAccuracy: 0.896652\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.252586.\tAccuracy: 0.898661\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.215454.\tAccuracy: 0.913170\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.207232.\tAccuracy: 0.918527\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.203965.\tAccuracy: 0.920908\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.177773.\tAccuracy: 0.931473\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.171250.\tAccuracy: 0.934375\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.172932.\tAccuracy: 0.933408\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.149994.\tAccuracy: 0.943527\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.147988.\tAccuracy: 0.944866\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.147724.\tAccuracy: 0.944345\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.133723.\tAccuracy: 0.948661\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.126224.\tAccuracy: 0.949330\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.127497.\tAccuracy: 0.949926\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.110930.\tAccuracy: 0.958482\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.107737.\tAccuracy: 0.960379\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.107241.\tAccuracy: 0.959301\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.097422.\tAccuracy: 0.962054\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.098425.\tAccuracy: 0.961161\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.097539.\tAccuracy: 0.962054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.87      1100\n",
      "           1       0.71      0.60      0.65       182\n",
      "           2       0.75      0.73      0.74       332\n",
      "\n",
      "    accuracy                           0.82      1614\n",
      "   macro avg       0.77      0.74      0.75      1614\n",
      "weighted avg       0.82      0.82      0.82      1614\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.700889.\tAccuracy: 0.716964\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.600450.\tAccuracy: 0.758482\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.553877.\tAccuracy: 0.776786\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.423663.\tAccuracy: 0.821429\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.406520.\tAccuracy: 0.831138\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.394616.\tAccuracy: 0.838318\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.336107.\tAccuracy: 0.864286\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.322955.\tAccuracy: 0.868415\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.317875.\tAccuracy: 0.871726\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.270623.\tAccuracy: 0.891071\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.259802.\tAccuracy: 0.896094\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.256085.\tAccuracy: 0.897396\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.229723.\tAccuracy: 0.910714\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.217281.\tAccuracy: 0.917188\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.212632.\tAccuracy: 0.918527\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.185148.\tAccuracy: 0.926786\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.177325.\tAccuracy: 0.931696\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.175242.\tAccuracy: 0.932813\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.152757.\tAccuracy: 0.941295\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.149908.\tAccuracy: 0.942187\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.151981.\tAccuracy: 0.942783\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.136536.\tAccuracy: 0.948438\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.132800.\tAccuracy: 0.949888\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.132910.\tAccuracy: 0.949479\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.120796.\tAccuracy: 0.951786\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.115209.\tAccuracy: 0.954464\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.115432.\tAccuracy: 0.955729\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.104208.\tAccuracy: 0.960714\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.098778.\tAccuracy: 0.963504\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.098179.\tAccuracy: 0.963542\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.94      0.86      1061\n",
      "           1       0.81      0.50      0.62       218\n",
      "           2       0.83      0.57      0.68       334\n",
      "\n",
      "    accuracy                           0.80      1613\n",
      "   macro avg       0.81      0.67      0.72      1613\n",
      "weighted avg       0.81      0.80      0.79      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.714342.\tAccuracy: 0.712054\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.604732.\tAccuracy: 0.757031\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.554060.\tAccuracy: 0.776786\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.432927.\tAccuracy: 0.821875\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.411552.\tAccuracy: 0.833705\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.398187.\tAccuracy: 0.839583\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.354842.\tAccuracy: 0.854464\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.338405.\tAccuracy: 0.863616\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.328522.\tAccuracy: 0.869196\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.293205.\tAccuracy: 0.884375\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.281777.\tAccuracy: 0.886384\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.272642.\tAccuracy: 0.890997\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.242921.\tAccuracy: 0.902679\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.231661.\tAccuracy: 0.909933\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.226934.\tAccuracy: 0.911979\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.197166.\tAccuracy: 0.921429\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.190274.\tAccuracy: 0.926562\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.189620.\tAccuracy: 0.927902\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.170387.\tAccuracy: 0.931250\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.163489.\tAccuracy: 0.935937\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.160440.\tAccuracy: 0.938616\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.147639.\tAccuracy: 0.942187\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.139959.\tAccuracy: 0.946205\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.140312.\tAccuracy: 0.946354\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.127235.\tAccuracy: 0.951786\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.120981.\tAccuracy: 0.953795\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.118643.\tAccuracy: 0.955357\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.115175.\tAccuracy: 0.953125\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.105941.\tAccuracy: 0.958594\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.105217.\tAccuracy: 0.959077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89      1126\n",
      "           1       0.79      0.64      0.71       185\n",
      "           2       0.76      0.68      0.72       302\n",
      "\n",
      "    accuracy                           0.84      1613\n",
      "   macro avg       0.81      0.75      0.77      1613\n",
      "weighted avg       0.84      0.84      0.84      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.670789.\tAccuracy: 0.724777\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.584297.\tAccuracy: 0.761719\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.545363.\tAccuracy: 0.779539\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.414809.\tAccuracy: 0.826116\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.399647.\tAccuracy: 0.834598\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.392588.\tAccuracy: 0.839658\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.335929.\tAccuracy: 0.861384\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.324611.\tAccuracy: 0.871205\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.324155.\tAccuracy: 0.870610\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.280420.\tAccuracy: 0.887054\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.272526.\tAccuracy: 0.891964\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.271128.\tAccuracy: 0.892708\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.232877.\tAccuracy: 0.910937\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.223572.\tAccuracy: 0.913170\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.223405.\tAccuracy: 0.913765\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.187199.\tAccuracy: 0.925670\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.183524.\tAccuracy: 0.928460\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.186284.\tAccuracy: 0.927307\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.165033.\tAccuracy: 0.933036\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.158398.\tAccuracy: 0.937723\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.158934.\tAccuracy: 0.936905\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.138668.\tAccuracy: 0.946429\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.131613.\tAccuracy: 0.950446\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.136234.\tAccuracy: 0.947396\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.113951.\tAccuracy: 0.959598\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.113039.\tAccuracy: 0.959487\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.120649.\tAccuracy: 0.955060\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.103614.\tAccuracy: 0.960491\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.103198.\tAccuracy: 0.959821\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.110947.\tAccuracy: 0.956622\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88      1088\n",
      "           1       0.80      0.64      0.71       193\n",
      "           2       0.86      0.57      0.68       332\n",
      "\n",
      "    accuracy                           0.83      1613\n",
      "   macro avg       0.83      0.72      0.76      1613\n",
      "weighted avg       0.83      0.83      0.82      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.960337.\tAccuracy: 0.670759\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.755049.\tAccuracy: 0.727790\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.668421.\tAccuracy: 0.752679\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.439394.\tAccuracy: 0.817634\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.425194.\tAccuracy: 0.824888\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.416577.\tAccuracy: 0.831176\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.368802.\tAccuracy: 0.849330\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.354608.\tAccuracy: 0.856808\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.350500.\tAccuracy: 0.859673\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.307736.\tAccuracy: 0.877902\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.297727.\tAccuracy: 0.882478\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.294908.\tAccuracy: 0.883482\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.263299.\tAccuracy: 0.896429\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.253064.\tAccuracy: 0.900893\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.249760.\tAccuracy: 0.900893\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.220261.\tAccuracy: 0.913616\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.211165.\tAccuracy: 0.915179\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.210410.\tAccuracy: 0.916295\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.190276.\tAccuracy: 0.927902\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.182244.\tAccuracy: 0.929911\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.180447.\tAccuracy: 0.929539\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.161785.\tAccuracy: 0.939509\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.154057.\tAccuracy: 0.942076\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.154231.\tAccuracy: 0.941815\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.141672.\tAccuracy: 0.946875\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.137777.\tAccuracy: 0.948438\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.137506.\tAccuracy: 0.948438\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.124435.\tAccuracy: 0.954241\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.123131.\tAccuracy: 0.953125\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.121215.\tAccuracy: 0.954539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.93      0.89      1114\n",
      "           1       0.79      0.67      0.72       180\n",
      "           2       0.80      0.62      0.70       319\n",
      "\n",
      "    accuracy                           0.84      1613\n",
      "   macro avg       0.81      0.74      0.77      1613\n",
      "weighted avg       0.83      0.84      0.83      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.870003.\tAccuracy: 0.675670\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.687585.\tAccuracy: 0.737835\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.615179.\tAccuracy: 0.761086\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.426375.\tAccuracy: 0.823438\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.406331.\tAccuracy: 0.834710\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.398697.\tAccuracy: 0.839063\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.352230.\tAccuracy: 0.860045\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.330736.\tAccuracy: 0.868862\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.325288.\tAccuracy: 0.869940\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.285172.\tAccuracy: 0.890402\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.271794.\tAccuracy: 0.894196\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.269253.\tAccuracy: 0.896280\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.237247.\tAccuracy: 0.910491\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.225240.\tAccuracy: 0.912277\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.221664.\tAccuracy: 0.912946\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.209144.\tAccuracy: 0.915179\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.194832.\tAccuracy: 0.921540\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.190568.\tAccuracy: 0.925000\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.162125.\tAccuracy: 0.933705\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.155296.\tAccuracy: 0.938616\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.156810.\tAccuracy: 0.938988\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.149386.\tAccuracy: 0.943304\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.140701.\tAccuracy: 0.946317\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.142229.\tAccuracy: 0.945387\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.134974.\tAccuracy: 0.949107\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.127063.\tAccuracy: 0.950893\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.125824.\tAccuracy: 0.951860\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.106899.\tAccuracy: 0.962723\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.104670.\tAccuracy: 0.963058\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.108001.\tAccuracy: 0.961310\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      1134\n",
      "           1       0.73      0.73      0.73       201\n",
      "           2       0.74      0.67      0.70       278\n",
      "\n",
      "    accuracy                           0.84      1613\n",
      "   macro avg       0.78      0.76      0.77      1613\n",
      "weighted avg       0.83      0.84      0.83      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.767096.\tAccuracy: 0.699554\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.640440.\tAccuracy: 0.749888\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.586060.\tAccuracy: 0.769345\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.437484.\tAccuracy: 0.821875\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.418477.\tAccuracy: 0.831585\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.409330.\tAccuracy: 0.832887\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.360777.\tAccuracy: 0.854241\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.345863.\tAccuracy: 0.862388\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.339440.\tAccuracy: 0.863914\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.297075.\tAccuracy: 0.882812\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.286162.\tAccuracy: 0.888281\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.284702.\tAccuracy: 0.888839\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.257887.\tAccuracy: 0.899330\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.241615.\tAccuracy: 0.906250\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.239287.\tAccuracy: 0.907068\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.215332.\tAccuracy: 0.918527\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.205133.\tAccuracy: 0.922879\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.202317.\tAccuracy: 0.923512\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.182906.\tAccuracy: 0.930357\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.174719.\tAccuracy: 0.934487\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.174544.\tAccuracy: 0.933705\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.161840.\tAccuracy: 0.938616\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.154100.\tAccuracy: 0.940513\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.153919.\tAccuracy: 0.940848\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.132842.\tAccuracy: 0.950000\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.130649.\tAccuracy: 0.950112\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.132120.\tAccuracy: 0.949926\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.126939.\tAccuracy: 0.952232\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.119504.\tAccuracy: 0.956250\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.118863.\tAccuracy: 0.956696\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.89      0.88      1131\n",
      "           1       0.73      0.66      0.69       180\n",
      "           2       0.70      0.64      0.67       302\n",
      "\n",
      "    accuracy                           0.82      1613\n",
      "   macro avg       0.77      0.73      0.75      1613\n",
      "weighted avg       0.82      0.82      0.82      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.779852.\tAccuracy: 0.697321\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.643950.\tAccuracy: 0.747879\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.590391.\tAccuracy: 0.766815\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.428074.\tAccuracy: 0.823661\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.410442.\tAccuracy: 0.830134\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.405881.\tAccuracy: 0.832440\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.355941.\tAccuracy: 0.853571\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.343287.\tAccuracy: 0.860938\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.340657.\tAccuracy: 0.861607\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.303318.\tAccuracy: 0.878125\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.288637.\tAccuracy: 0.884040\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.288371.\tAccuracy: 0.885342\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.255208.\tAccuracy: 0.897991\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.243242.\tAccuracy: 0.903795\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.243020.\tAccuracy: 0.905134\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.218555.\tAccuracy: 0.914955\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.211002.\tAccuracy: 0.919978\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.209994.\tAccuracy: 0.919866\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.190562.\tAccuracy: 0.924107\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.180355.\tAccuracy: 0.929911\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.179908.\tAccuracy: 0.931324\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.161744.\tAccuracy: 0.937723\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.154901.\tAccuracy: 0.939732\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.154261.\tAccuracy: 0.940923\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.151072.\tAccuracy: 0.940625\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.144336.\tAccuracy: 0.943862\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.139439.\tAccuracy: 0.946429\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.134194.\tAccuracy: 0.947768\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.125538.\tAccuracy: 0.950781\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.124031.\tAccuracy: 0.952307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89      1100\n",
      "           1       0.77      0.76      0.77       187\n",
      "           2       0.80      0.65      0.71       326\n",
      "\n",
      "    accuracy                           0.84      1613\n",
      "   macro avg       0.81      0.78      0.79      1613\n",
      "weighted avg       0.84      0.84      0.84      1613\n",
      "\n",
      "Epoch: 0/10.\tBatch: 35.\tLoss: 0.683170.\tAccuracy: 0.720089\n",
      "Epoch: 0/10.\tBatch: 70.\tLoss: 0.602636.\tAccuracy: 0.755469\n",
      "Epoch: 0/10.\tBatch: 105.\tLoss: 0.561802.\tAccuracy: 0.772098\n",
      "Epoch: 1/10.\tBatch: 35.\tLoss: 0.432071.\tAccuracy: 0.823661\n",
      "Epoch: 1/10.\tBatch: 70.\tLoss: 0.422767.\tAccuracy: 0.827344\n",
      "Epoch: 1/10.\tBatch: 105.\tLoss: 0.414228.\tAccuracy: 0.830655\n",
      "Epoch: 2/10.\tBatch: 35.\tLoss: 0.359666.\tAccuracy: 0.847545\n",
      "Epoch: 2/10.\tBatch: 70.\tLoss: 0.349701.\tAccuracy: 0.856027\n",
      "Epoch: 2/10.\tBatch: 105.\tLoss: 0.344098.\tAccuracy: 0.860045\n",
      "Epoch: 3/10.\tBatch: 35.\tLoss: 0.300523.\tAccuracy: 0.883259\n",
      "Epoch: 3/10.\tBatch: 70.\tLoss: 0.291498.\tAccuracy: 0.883929\n",
      "Epoch: 3/10.\tBatch: 105.\tLoss: 0.283905.\tAccuracy: 0.886607\n",
      "Epoch: 4/10.\tBatch: 35.\tLoss: 0.243430.\tAccuracy: 0.906473\n",
      "Epoch: 4/10.\tBatch: 70.\tLoss: 0.239797.\tAccuracy: 0.906920\n",
      "Epoch: 4/10.\tBatch: 105.\tLoss: 0.238823.\tAccuracy: 0.907738\n",
      "Epoch: 5/10.\tBatch: 35.\tLoss: 0.214133.\tAccuracy: 0.915625\n",
      "Epoch: 5/10.\tBatch: 70.\tLoss: 0.209377.\tAccuracy: 0.916964\n",
      "Epoch: 5/10.\tBatch: 105.\tLoss: 0.204468.\tAccuracy: 0.919866\n",
      "Epoch: 6/10.\tBatch: 35.\tLoss: 0.176953.\tAccuracy: 0.932813\n",
      "Epoch: 6/10.\tBatch: 70.\tLoss: 0.176500.\tAccuracy: 0.934040\n",
      "Epoch: 6/10.\tBatch: 105.\tLoss: 0.174593.\tAccuracy: 0.933259\n",
      "Epoch: 7/10.\tBatch: 35.\tLoss: 0.162024.\tAccuracy: 0.936161\n",
      "Epoch: 7/10.\tBatch: 70.\tLoss: 0.155946.\tAccuracy: 0.941071\n",
      "Epoch: 7/10.\tBatch: 105.\tLoss: 0.151080.\tAccuracy: 0.943378\n",
      "Epoch: 8/10.\tBatch: 35.\tLoss: 0.138476.\tAccuracy: 0.945312\n",
      "Epoch: 8/10.\tBatch: 70.\tLoss: 0.137289.\tAccuracy: 0.945536\n",
      "Epoch: 8/10.\tBatch: 105.\tLoss: 0.137110.\tAccuracy: 0.946429\n",
      "Epoch: 9/10.\tBatch: 35.\tLoss: 0.123551.\tAccuracy: 0.952455\n",
      "Epoch: 9/10.\tBatch: 70.\tLoss: 0.122840.\tAccuracy: 0.952902\n",
      "Epoch: 9/10.\tBatch: 105.\tLoss: 0.122050.\tAccuracy: 0.953646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88      1107\n",
      "           1       0.80      0.67      0.73       186\n",
      "           2       0.71      0.71      0.71       320\n",
      "\n",
      "    accuracy                           0.83      1613\n",
      "   macro avg       0.79      0.76      0.77      1613\n",
      "weighted avg       0.83      0.83      0.83      1613\n",
      "\n",
      "macro results are\n",
      "average precision is 0.826100\n",
      "average recall is 0.827921\n",
      "average f1 is 0.822860\n",
      "Saving model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:993: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "!python lstm_bi.py -f GloVe/glove.twitter.27B.200d.txt -d 200 --tokenizer glove --loss categorical_crossentropy --optimizer adam --initialize-weights glove --learn-embeddings --epochs 10 --batch-size 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BiLSTM + Glove + LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 200\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16132\n",
      "Model Type: logistic\n",
      "Precision(avg): 0.898 (+/- 0.011)\n",
      "Recall(avg): 0.899 (+/- 0.011)\n",
      "F1-score(avg): 0.897 (+/- 0.011)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:993: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed:   30.1s finished\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier.py logistic bi_lstm_glove.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#BiLSTM + Glove + Hybrid Feature(TF_IDF_WA)+LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Dimension: 200\n",
      "Tweets loaded from pickled file.\n",
      "Tweets selected: 16132\n",
      "16132 200 200 16132\n",
      "Model Type: logistic\n",
      "Precision(avg): 0.908 (+/- 0.008)\n",
      "Recall(avg): 0.909 (+/- 0.008)\n",
      "F1-score(avg): 0.908 (+/- 0.008)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\smart_open\\ssh.py:34: UserWarning: paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress\n",
      "  warnings.warn('paramiko missing, opening SSH/SCP/SFTP paths will be disabled.  `pip install paramiko` to suppress')\n",
      "C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2516: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1029: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:993: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Narendra\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  10 out of  10 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "!python nn_classifier_tfidf.py logistic bi_lstm_glove.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
